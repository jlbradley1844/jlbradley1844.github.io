---
title: Generative AI Wil Be a Net Productivity Drain
category: article
---

## Generative AI (and ChatGPT) Wil Be a Net Productivity Drain

While everyone is pushing out their hot takes and grabbing eyebals, I'm going to jump into the fray
with an unusual hot take: Generative AI solutions, such as ChatGPT, will be a net productivity drain.
They will not disrupt the workforce measurably and will not contribute to GDP measurably either.

_Introduction:_ It can take some time to figure out if a technology is for good or ill. I like to
think of myself as an informed observer, having worked in technology a number of years. I also recognize
that my track record is not so great that I've been able to benfit myself. It is easy to spot problematic
technologies; much harder to make money off of them.

So for instance, when I heard of Tinder shortly after getting married and immediately thought "BAD IDEA,"
I may have been right, but I was in no position to benefit. And the fact something seems like a bad idea
isn't itself enough to doom a technology. Meanwhile, I investigated cryptocurrencies a good two years
before recognizing it as a ponzi scheme. In the mid-nineties, I concluded with a business partner that
"the internet" itself was not enough to make money off of and almost all internet startups were doomed.
I was correct, but also missed my chance to make a mint off of the bubble before it burst.

So my track record isn't great. Yet the overwhelming consensus about ChatGPT and the other impressive-looking
related projects is _this changes everyting_. I maintain it does not, and I'll list the reasons why.

_The key problem: it does _not_ know your business._

The whole thesis undermining the claims of software automation surpremacy was laid out in a famous article
by Fred Brooks in 1986 - "No Silver Bullet," in _IEEE Computer_. The article aimed at the automated "no code"
solutions that many software houses were selling to business. Fred Brooks' analysis proved to most readers
why such solutions may improve productivity at the margins but never by orders of magnitude.

His analysis was the following: the chief reason software takes time to develop is _complexity_. It
is incredibly complicated. Now, there are two types of complexity:
* "Accidental complexity". This is all of the tasks involved with writing, building and maintaining programs.
* "Essential complexity". This is the work involved with understanding the business, determining program requirements, determining which algorithms to use, and adapting all of it to the underlying business that the software supports.
His point was that these no-code tools and productivity increases were all aimed at eliminating
"accidental complexity." And indeed, if you look at the history of software engineering, there has been
a steady march in the decrease in accidental complexity of the code. Thanks to such tooling, software
engineers are far more productive than their peers of the eighties.

They are not, however, orders-of-magnitude more effective. The underlying business challenges
remain.

So when I look at programmers who boast that ChatGPT has made them immeasurably more productive,
I wonder what business they're in! ChatGPT does not replace the task of writing code _from scratch_.
It replaces the task of copying boilerplate code from elsewhere. Indeed, the boilerplate code must
exist on the internet already - _because that's why ChatGPT can copy from it!_. Indeed, many of the
demonstrations of "creative solutions" to programming problems were found to practically duplicate 
the same problems it was traied on. It's been shown that for truly novel problems - ones for which
solutions do not appear on the internet - ChatGPTs output is little more than garbage. The question is
why anyone should be surprised. These programs aren't intelligent! They're just very good at copying
and organizing the thoughts of others.

So: perhaps a marginally-better way of scouring the internet and putting together boilerplate code.
Useful? Yes. Revolutionary? Hardly.

If you have an undifferentiated business, yes, something like ChatGPT sounds like it could be immensely useful.
To which I would ask - is that business making money? If your answer is "yes,"
then it's because you have some sort of value add - networks connections, specialized knowledge, other
"long tail" technical knowledge - something that allows you to establish a business. _This is exactly the
thing that Generative AI cannot give you._ Generative AI does not replace or extend your contact database;
it cannot understand particulars about the business you operate in.

What it does do is simplify certain routine work. It does not replace dayslong tasks of research and learning
It replaces tasks that used to take a half-hour of googling with a minute of queries. It replaces an hours-long
search of clipart databases with a few minutes of image generation. As a professional, these are tedious tasks,
and it's good to have an assistent help you.But it's only that - an assistant. It will save minutes of your time.
It will not replace months of labor by a new hire.

The inevitable retort is that "the AIs will only get better!" But will they? What is needed is the sort of
domain knowledge that is embedded into your business. For the AI to get better than that, you would need
to actually either
a. train your own local AI model in knowledge that you yourself have collected, complete with all of the IT work that would entail, or 
b. upload loads of hard-earned proprietary IP into a publicly available AI brain, which will Borg all the knowledge you uploaded to it and sell it back to you _and your competitors_ in a somewhat more usable format.
Given that you're not stupid enough to do b., and probably not smart enough to both do a. and work on
your business, then this will not help you.

So at best a marginal improvement to your business. But that's still a net positive, not a negative!
Why do I say this will be a net drag on productivity?

_The Killer Apps of Genrative AI_

There are several cases where this sort of AI really can improve productivty by orders of magnitude.
These are things that don't require specialized knowledge and you generally don't care about the
occasional outright falsehood.
What is it in?

_"Content" creation_. Note that I say "content," not writing. This is the classic use of ChatGPT - the
generation of good looking and grammatically-correct but generally uninteresting and unoriginal
sort of writing that fills the internet. If you want plausible-sounding nonfiction that sounds like
a wikipedia article, or fiction that sounds like a composite of a thousand other works of fiction,
this fits the bill. 

_Ad copy_. The same qualities that make ChatGPT good for cranking out anodyne prose are also
excellent at generating reams of ad copy. The inability to tell fact from fiction could be a
bug, not a feature.

_Public Relations_. Similar to ad copy, this is the generation of content skewed to a particular
viewpoint. The ability to generate a broad variety of messages, all hitting the same broad
points, will allow more realistic astroturfing initiatives, as it is more difficult to use
text similarities to trace back to the same source.

_Misinformation_. This is perhaps the killer app. This leverages the ability to spew loads of
fictitious information in a professional confident voice without any bothersome people with a
conscience. The AI engine can be fine-tuned to spread any variety of lies that can be desired.
Such bots can even serve as live chatbots,

All of the above are currently paid positions. But they are also something else - something
that has been described in other writings as "bullshit jobs." Some of these jobs contribute
little to society and productive enterprises. Most, however, are a net drag on society.


