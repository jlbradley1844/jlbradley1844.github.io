http://freakonomics.com/podcast/launch-behavior-change-revolution/

[Adam] Grant: "Most behavior change is actually not desirable. That’s
one of the major things that stands in our way. The thing that we’re
trying to convince ourselves or others to do is not actually something
that we want to do or that they want to do."

Kurt Lewin was a German-American psychologist who in the early 20th
century developed several ideas that became central to modern
psychology. Among them: that people’s behavior is strongly driven by
two main external forces. 

[Daniel] KAHNEMAN: "There are driving forces that drive you in a particular
direction. There are restraining forces. Which are preventing you from
going there. The notion that Lewin offers is that behavior is an
equilibrium between the driving and the restraining forces. You can
see that the speed at which you drive, for example, is an
equilibrium. When you are rushing some place, you feel tired, or
you’re worried about police. There is an equilibrium speed. A lot of
things can be described as an equilibrium between driving and
restraining forces. Lewin’s insight was that if you want to achieve
change in behavior, there is one good way to do it and one bad way to
do it. The good way to do it is by diminishing the restraining forces,
not by increasing the driving forces. That turns out to be profoundly
non-intuitive." 

In most cases, Kahneman explained, we try to change people’s behavior
with a mish-mash of arguments, incentives, and threats. 

KAHNEMAN: "Diminishing the restraining forces is a completely
different kind of activity, because instead of asking, “How can I get
him or her to do it?” it starts with a question of, “Why isn’t she
doing it already?” Very different question. “Why not?” Then you go one
by one systematically, and you ask, “What can I do to make it easier
for that person to move?” 

"It turns out that the way to make things easier is almost always by
controlling the individual’s environment, broadly speaking. By just
making it easier. Is there an incentive that work against it? Let’s
change the incentives. If there is social pressure? If there is
somebody who is against it, I want to influence B. But there is A in
the background, and it’s actually A who is a restraining force on
B. Let’s work on A, not on B. I have never heard a psychological idea
that impressed me quite as much as this one, perhaps because I was at
an impressionable age."

KAHNEMAN: "What you can hope for is what is called practically
significant improvement, which is usually a few percent. If you get a
few percent at relatively low cost, that’s a success." 

==================================

https://www.nytimes.com/2017/12/29/opinion/sunday/the-only-way-to-keep-your-resolutions.html

[David DeSteno, a professor of psychology at Northeastern University,
is the author of the forthcoming book “Emotional Success: The Power of
Gratitude, Compassion, and Pride.”]

I believe it did; we’re just ignoring it. That tool is our social
emotions. These are the emotions — things like gratitude and
compassion — that support the positive aspects of social life. For
years I’ve been studying the effects of these emotions on
decision-making and behavior, and I’ve found that unlike reason and
willpower, they naturally incline us to be patient and persevere. When
you are experiencing these emotions, self-control is no longer a
battle, for they work not by squashing our desires for pleasure in the
moment but by increasing how much we value the future.

...
 
The research on self-control shows that willpower, for all its
benefits, wanes over time. As we try to make ourselves study, work,
exercise or save money, the mental effort to keep focused and
motivated increases until it seems too difficult to bear. 

Worse, exerting willpower can take a psychological and physical
toll. As recent work by the Northwestern University psychologist Greg
Miller has shown, willing oneself to be “gritty” can be quite
stressful. Studying about 300 teenagers from socially and economically
disadvantaged backgrounds, Professor Miller found that those who were
better at using self-control did have more success when it came to
resisting temptations, but at a cost to their health. Their bodies
suffered not only from increased stress responses, but also from
premature aging of their immune cells. 

At moderate levels, the tendency to pursue achievement through
willpower and rational analysis can be a boon. But at higher levels,
it’s a detriment to well-being — especially if you fail. When people
who are exceedingly focused and dedicated to using force of will to
achieve their goals come up short, they report a hit to their
well-being that is 120 percent greater than that reported by those who
follow a less austere and stressful path.

...
When it comes to making such short-term sacrifices, most of us don’t
rely on a cold, rational analysis of costs and benefits. We don’t
normally calculate what’s to be gained by helping someone else. We
just feel like we should. It’s our emotions — specifically, gratitude,
compassion and an authentic sense of pride (not hubris) — that push us
to behave in ways that show self-control. 

...
What these findings show is that pride, gratitude and compassion,
whether we consciously realize it or not, reduce the human mind’s
tendency to discount the value of the future. In so doing, they push
us not only to cooperate with other people but also to help our own
future selves. Feeling pride or compassion has been shown to increase
perseverance on difficult tasks by over 30 percent. Likewise,
gratitude and compassion have been tied to better academic
performance, a greater willingness to exercise and eat healthily, and
lower levels of consumerism, impulsivity and tobacco and alcohol use. 

If using willpower causes stress, using these emotions actually heals:
They slow heart rate, lower blood pressure and reduce feelings of
anxiety and depression. By making us value the future more, they ease
the way to patience and perseverance. 

-------------------------------

https://www.washingtonpost.com/news/wonk/wp/2018/01/01/the-science-of-keeping-your-new-years-resolution/

This illustrates that if we can get people (or ourselves) to try
something new intensively for as little as a month (even with an
instrument as blunt as a cash payment), we can kick-start lasting
behavior change. So even if you can’t promise yourself to stick with
something for long, there’s a huge benefit in putting in a burst of
energy for a few weeks — it may pay off for longer than you think.
...

What this suggests is that the perfect goal to set for yourself is
probably a tough one but with the explicit allowance for a mulligan or
two so you won’t be discouraged by the occasional slip up.
...
Research points to the benefits of what’s called a “piggybacking”
strategy. Piggybacking involves linking something you’d like to start
doing regularly — like flossing or eating an apple a day — with
something you already do regularly, like brushing your teeth or
drinking a morning cup of coffee. In one small study, people
attempting to kick-start a flossing habit were more successful when
they were prompted to floss after brushing their teeth rather than
vice versa. 

Related to piggybacking is an idea my collaborators and I call
temptation bundling. Temptation bundling means linking something you’d
like to do more often with something indulgent that you crave. For
instance, imagine you love binge-watching “Game of Thrones” but feel
guilty about doing this at home when you should be spending quality
time with family. Imagine you’d also like to start a gym habit. Your
temptation bundle might be to watch “Game of Thrones” only when
exercising at the gym. You’d stop wasting time at home on TV and start
craving trips to the gym to find out what happens in the next
episode. 

-----------------

https://fivethirtyeight.com/features/i-was-a-meditation-skeptic-until-i-tried-to-make-my-case/

There is some limited evidence to suggest that meditation might help
with some ailments and may produce measurable changes in the
brain. It’s no miracle cure, and there’s still a lot of science left
to do, especially about the kind of casual meditation people may fit
into a busy day. But in my rush to doubt my therapist’s advice, I
forgot that skepticism can sometimes be as flawed as the science it
seeks to temper.

 The 2014 meta-analysis was careful to note that “any firm claims
 about whether meditation truly causes differences in brain structure
 are still premature.” Mindfulness research is also easily
 misrepresented. In 2005, Sara Lazar, a professor at Harvard and
 researcher at Massachusetts General Hospital, and others published a
 study that found differences in the brains of people who practice
 mindfulness, compared with those who don’t. But that’s all it showed
 — not that mindfulness caused differences in brain chemistry. Since
 then, Lazar said, the science has reached the point where we can show
 that meditation has a direct effect. But her experience is a reminder
 that mindfulness science can fall victim to the media hype cycle.

---------------

https://arstechnica.com/science/2017/08/meta-analysis-shows-psychotherapy-leads-to-long-term-personality-change/

A meta-analysis published recently in Psychological Bulletin reports
that a variety of different therapeutic techniques result in positive
changes to personality, especially when it comes to neuroticism, that
last over a considerable period of time.

Personality is, as your intuition might tell you, relatively
stable—people who start out gregarious and adventurous tend to stay
gregarious and adventurous throughout their lives. Assessments of
people’s personality traits taken at different times tend to agree
pretty well with each other. But that doesn’t mean personality is
static: personal growth, life experiences, and age all play their
part, and people’s personalities do change somewhat throughout their
lives—usually for the better. 
...
Quite a few studies have found the positive effects of therapy, but
the state of the art in evidence is the meta-analysis, which combines
data from multiple studies on the same topic. Brent Roberts, a
researcher at the University of Illinois, Urbana-Champaign, led a team
that used data from 207 studies and more than 20,000 participants to
explore the effects of therapy on personality. 

They found that personality change occurred and was robust for
different therapy types (including cognitive behavioral therapy,
psychodynamic therapy, and other kinds). It didn’t differ much between
techniques, although patients who were hospitalized showed the least
amount of change. Patients with anxiety disorders saw the greatest
improvement, while those with eating disorders or substance abuse saw
the smallest changes. 

not all personality traits saw the same effect. Any change in openness
to experience wasn’t reliable across studies, while conscientiousness
and agreeableness showed only small changes. Extraversion showed a
larger change, and the effect on neuroticism was dramatic. Neuroticism
tends to decrease from young adulthood into middle age, and “therapy
lasting four or more weeks achieves half that amount of change,” the
authors write. And “personality levels remained altered after more
than a full year,” they note. 
...
And although Roberts and his colleagues corrected for publication bias
in their analyses, there was “pervasive evidence” of this being a
problem, they note. This “indicates a need for preregistered,
controlled studies,” they write, conducted “by individuals who are not
motivated to show the effectiveness of any given therapy.” 

--------------------

https://www.artofmanliness.com/2013/08/05/what-strengthens-and-weakens-our-integrity-part-i-why-small-choices-count/

For a long time it was thought that people made such decisions by
employing a rational cost/benefit analysis. When tempted to engage in
an unethical behavior, they would weigh the chances of getting caught
and the resulting punishment against the possible reward, and then act
accordingly. 
 
However, experiments by Dr. Ariely and others have shown that far from
being a deliberate, rational choice, dishonesty often results from
psychological and environmental factors that people typically aren’t
even aware of.
...
This, Ariely, had discovered, went to the root of people’s true
motivations for cheating. Rather than decisions to be dishonest only
being made on the basis of risk vs. reward, they’re also greatly
influenced by the degree to which they’ll affect our ability to still
see ourselves in a positive light. Ariely explains these two opposing
drives:

“On one hand, we want to view ourselves as honest, honorable
people. We want to be able to look at ourselves in the mirror and feel
good about ourselves (psychologists call this ego motivation). On the
other hand, we want to benefit from cheating and get as much money as
possible (this is the standard financial motivation). Clearly these
two motivations are in conflict. How can we secure the benefits of
cheating and at the same time still view ourselves as honest,
wonderful people?

This is where our amazing cognitive flexibility comes into
play. Thanks to this human skill, as long as we cheat by only a little
bit, we can benefit from cheating, and still view ourselves as
marvelous human beings. This balancing act is the process of
rationalization, and it is the basis of what we’ll call the ‘fudge
factor theory.'”

Where you draw the line and how wide you allow your fudge factor
margin to become is influenced by a variety of external and internal
conditions, the most important one being this: simply taking a first,
however small, dishonest step. Other conditions can increase or
decrease your likelihood of taking that initial step, and we’ll
discuss them in the subsequent parts of this series. But since whether
or not you make that first dishonest decision very often constitutes
the crux of the matter, let us begin there. 
...
In social psychologists Carol Tavris and Elliot Aronson illustrate the
way in which a single decision can greatly alter the path we take and
the strength of our integrity. They use the example of two college
students who find themselves struggling on an exam that will determine
whether or not they get into graduate school. They are “identical in
terms of attitudes, abilities, and psychological health,” and are
“reasonably honest and have the same middling attitude towards
cheating.” Both students are presented with the chance to see another
student’s answers and both struggle with the temptation. But one
decides to cheat and the other does not. “Each gain something
important, but at a cost; one gives up integrity for a good grade, the
other gives up a good grade to preserve his integrity.”

What will each student think and tell himself as he reflects on his
decision? As we explained in our series on personal responsibility,
when you make a mistake or a choice that’s out of line with your
values, a gap opens up between your actual behavior and your
self-image as a good, honest, competent person. Because of this gap,
you experience cognitive dissonance – a kind of mental anxiety or
discomfort. Since humans don’t like this feeling of discomfort, our
brains quickly work to bridge the divide between how we acted and our
positive self-image by explaining away the behavior as really not so
bad after all.
...
What Ariely found is that participants who just cheated here and there
at the start of the experiment would eventually reach an “honesty
threshold,” the point where they would think: “What the hell, as long
as I’m a cheater, I might as well get the most out of it.” They would
then begin cheating at nearly every opportunity. The first decision to
cheat led to another, until their fudge factor margin stretched from a
sliver into a yawning chasm, and concerns about integrity fell right
off the cliff.
...
What this means is that if you want to maintain your integrity, the
best thing you can do is to never take that first dishonest step. No
matter how small and inconsequential a choice may seem at the time, it
may start you down a path that tarnishes your moral compass, leads you
to commit more serious misdeeds, and causes you to compromise your
fundamental principles.

Ariely argues that not only is preventing ourselves from taking a
first dishonest step so crucial, so is curbing small infractions in
society as well. While he admits that it’s tempting to dismiss
first-time mistakes as no big deal, his research has shown that we
“should not excuse, overlook, or forgive small crimes, because doing
so can make matters worse.” Instead, by cutting down “on the number of
seemingly innocuous singular acts of dishonesty…society might become
more honest and less corrupt over time.” This need not involve more
regulations or zero-tolerance policies, which Ariely doesn’t think are
effective, but rather instituting more subtle checks to personal and
public integrity, some of which we’ll discuss in the next parts in
this series. 

Obviously, not everyone who makes one bad choice ends up morally
depraved and utterly crooked. Many of us are able to make a single
mistake, or even several, but then get back on track again. This is
because various conditions not only make it more or less likely that
we’ll make that first dishonest decision, but also increase or
decrease our chances of turning ourselves around once we start down an
unethical road. 
...
main sources:
The Honest Truth About Dishonesty: How We Lie to Everyone–Especially
Ourselves by Dan Ariely
Mistakes Were Made (But Not By Me) by Carol Tavris and Elliot Aronson

------------------------------------------------------
https://blogs.scientificamerican.com/observations/moral-enhancement-is-science-fiction-not-science-fact/

Indeed, with so many troubles caused by immoral behavior, especially
with populations such as psychopaths, the appeal of a neuroscientific
“fix” was immense. Other drugs, such as stimulants, have also been
considered to further this aim and so have brain stimulation devices,
including transcranial direct current stimulation and deep brain
stimulation.

By itself, the idea of improving morality is based on laudable
intentions. However, there are two major questions that need to be
addressed before it becomes feasible: are the biomedical means
currently at our disposal more effective than traditional methods and
are the aims clear or misguided?

Let’s start with the means. Even though many of the proposed
interventions could in fact influence morally relevant behavior, the
effects are either not real enhancements, or worse, they are clearly
negative in terms of behavior or side effects, such as addiction.I
will stick with the example of oxytocin to illustrate this point. The
increase in trust and cooperation oxytocin might convey is limited to
members of one’s own “tribe.” Modern societies have more than one
ethnic, religious and racial group, however, so it is very troubling
to realize that oxytocin actually decreases cooperation with
outsiders. Even worse, it selectively promotes ethnocentrism,
favoritism, parochialism, and even pre-emptive aggression towards
those that are different.
...
But what about the aims? Even if the means are not yet there, if the
aims are good, scientific progress might provide the means in due
time. Well, there is a problem there as well. My past and ongoing
research shows that moral judgment is based on a balance of specific
intuitive evaluations: in any given situation, we quickly evaluate the
person involved, the actions they are trying to accomplish and the
consequences this would bring to others. The possibility of modulating
or enhancing any specific part of the moral judgment process might
result in unbalanced moral intuitions.
...
In fact, there is evidence to suggest that this is where things go
wrong with psychopaths—their judgment is dominated by evaluation of
consequences, which leads to inferences that are abhorrent to normal
people, that is, those who have the balance of intuitions intact. 

-----------------------------
https://aeon.co/essays/what-plato-knew-about-behavioural-economics-a-lot

...many of [Plato's] insights are remarkably similar to the descriptions of the
cognitive biases found by Kahneman and Tversky. Seminal papers in
behavioural economics are highly cited everywhere from business and
medical schools to the social sciences and the corporate world. But
the earlier explorations of the same phenomenon by Greek philosophy
are rarely appreciated. Noticing this continuity is both an
interesting point of intellectual history and a potentially useful
resource: Plato not only identified various specific weaknesses in
human cognition, he also offered powerful proposals for how to
overcome these biases and improve our reasoning and behaviour.

Many of Plato’s dialogues dramatise the habits and processes that lead
humans to false conclusions. He depicts people believing what they
want or what they are predisposed to believe (confirmation bias);
asserting whatever comes most readily to mind (availability bias);
reversing their opinions about identical propositions based on the
language in which the propositions are presented (framing); refusing
to relinquish current opinions simply because these happen to be the
opinions they currently possess (a cognitive version of loss
aversion); making false inferences based on the size and
representativeness of a sample of a broader population
(representativeness heuristic); and judging new information based on
salient current information (a version of anchoring). And this is only
a partial inventory of the mental errors that he catalogues and
dramatises.
...
Plato understood that susceptibility to distorted reasoning was a
matter of ethics as well as psychology. This does not mean anything as
simple as ‘bad people are more vulnerable to cognitive biases’. But
consider his diagnosis of misanthropy and other sampling errors, which
stem from ‘the too great confidence of inexperience’. In the Apology,
Socrates claims to be wiser than other men only because he knows that
which he does not know. When Kahneman writes that we are ‘blind to our
blindness’, he is reviving the Socratic idea that wisdom consists in
seeing one’s blindness: knowing what you do not know.

Intellectual humility and overconfidence can stem from purely
cognitive processes, but they are also correctly understood as moral
achievements or failings. Someone who always thinks that he is right
about everything, however little he knows, is making a moral as well
as a mental mistake. Similarly, the cultivation of intellectual
humility is, in part, the cultivation of an ethical virtue. Many of
the early Socratic dialogues end in uncertainty: the characters are
reduced to what in ancient Greek was called aporia, and is often
rendered in English as ‘perplexity’, ‘bafflement’, or ‘confusion’.

--------------------------------
https://aeon.co/essays/how-politeness-became-a-tool-of-radical-democratic-politics

18th-century Britons and Americans believed that politeness was
essential for a free society. Autocrats shouted, cursed and
berated. But they sought only obedience. Leading a more open society
required respect for other people, sensitivity to their expectations
and concerns. By the time of Jefferson’s ranking, politeness had been
part of the project of challenging authoritarian rule for more than a
century.

Later in 1808, Jefferson explained the importance of politeness more
fully. The president’s 16-year-old grandson, Thomas Jefferson
Randolph, had recently left home for further education in
Philadelphia. ‘Safety’ in this situation, Jefferson suggested,
required three qualities: moral virtue, ‘prudence’, and ‘good humour’
supported by ‘politeness’. He explained further that politeness was
‘artificial good humour’, the habits and discipline that filled in
when good humour flagged. It was, therefore, ‘an acquisition of
first-rate value’. Consideration for other people, refraining from
disputes in company, and sacrificing one’s own ‘conveniences and
preferences’ to please others could ‘win’ their ‘good will’.
....
Britons and Americans of the 18th century applied these ideals of
sympathy and respect to public as well as personal
relationships. Seeking restrained and responsive leadership, the
18th-century ‘politics of politeness’ offered a powerful challenge to
angry and overbearing authoritarian rule. For many contemporaries,
this critique often seemed broader and more compelling than the
discussions of legal and constitutional issues that are better known
today.

---------------------------------------
https://blogs.scientificamerican.com/observations/why-we-forgo-self-interest-for-others-sake/
_Scientific American_, Molly Crockett

Over the past several years, with collaborators at University College
London, I’ve been probing this question in the laboratory. 
...
These findings echo centuries-old ideas about human morality. In his
Theory of Moral Sentiments, the philosopher Adam Smith described the
conscience as an “impartial spectator”, guiding our choices by
directing inwards the spotlight we regularly shine on others’
misdeeds. Our research suggests that this is exactly what our
prefrontal cortex might be doing—when we’re making a moral decision,
like whether to take money from a lost wallet, our prefrontal cortex
simulates how others might blame us and adjusts the values of our
options accordingly, even when no one is watching. The construction of
moral values in the brain seems to incorporate the anticipated or
internalized judgments of others.

---------------------------------
https://www.vox.com/first-person/2017/4/1/15142744/mike-pence-billy-graham-rule
Vox · by Karen Swallow Prior · April 1, 2017 

But the good part of this story is that despite working for nearly two
decades at an evangelical university, I’ve had only two or three such
encounters with the Billy Graham rule. While I have tremendous respect
for men who place their marriages before their work, such a rule
befits the world of Mad Men more than the modern-day work world where
women are to be treated as equals. But even more importantly, good
character is even more trustworthy than the most well-intentioned
rules.

Virtue ethics is better than the Billy Graham rule.

Virtue ethics relies on moral character that is developed through good
habits rather than rules or consequences for the governing of
behavior. Aristotle defined virtue as the mean between two extremes,
one of excess and one of deficiency. It is a habit of moral character,
which, because it is a habit, becomes a kind of second nature. As
Aristotle explained, it does not depend upon rules. 
...
Prudence, in fact, is what seems to be missing from the conversation
about the vice president’s “rules.” And I don’t mean prudence in the
way that some supporters of the Billy Graham rule are using the
term. Prudence as properly understood is a virtue, not a rule. 

It is the virtue most applicable in the context of guarding against
workplace romances, the habit of making right decisions. Prudence,
which literally means foresight, is the mean between cunning and
negligence. It is wisdom in action.
...
 I would be unable to serve half of my students if I had a rule not to
 meet with a man alone, and the same would be true of my male
 colleagues and their students. On the other hand, because of this
 necessity, my school (like most) has windows on all office doors and
 a rule that those windows are not to be covered. This is prudent. The
 lack of any guiding principles is a deficiency, specifically the vice
 of negligence.

The opposite vice, the excess of prudence, is cunning. Cunning in this
context manifests itself in a particular way. Cunning foresees too
much of sex too much of the time.

------------------------------------
https://blogs.scientificamerican.com/guest-blog/how-the-science-of-blue-lies-may-explain-trumps-support/
How the Science of "Blue Lies" May Explain Trump's Support
Scientific American · by Jeremy Adam Smith · January 17, 2018 

How does the former reality-TV star get away with it? How can he tell
so many lies and still win support from many Americans?

Journalists and researchers have suggested many answers, from a
hyperbiased, segmented media to simple ignorance on the part of GOP
voters. But there is another explanation that no one seems to have
entertained. It is that Trump is telling “blue lies”—a psychologist’s
term for falsehoods, told on behalf of a group, that can actually
strengthen bonds among the members of that group.
...
Blue lies are a different category altogether, simultaneously selfish
and beneficial to others—but only to those who belong to your
group. As University of Toronto psychologist Kang Lee explains, blue
lies fall in between generous white lies and selfish “black”
ones. “You can tell a blue lie against another group,” he says, which
makes it simultaneously selfless and self-serving. “For example, you
can lie about your team’s cheating in a game, which is antisocial but
helps your team.”
...
This research—and these stories—highlights a difficult truth about our
species: we are intensely social creatures, but we are prone to divide
ourselves into competitive groups, largely for the purpose of
allocating resources. People can be prosocial—compassionate,
empathetic, generous, honest—in their group and aggressively
antisocial toward out-groups. When we divide people into groups, we
open the door to competition, dehumanization, violence—and socially
sanctioned deceit.

“People condone lying against enemy nations, and since many people now
see those on the other side of American politics as enemies, they may
feel that lies, when they recognize them, are appropriate means of
warfare,” says George Edwards, a political scientist at Texas A&M
University and one of the country’s leading scholars of the
presidency.
----------------------------------------
https://www.theguardian.com/world/2015/mar/03/what-scares-the-new-atheists
"What Scares the New Atheists" - John Gray
The Guardian March 3, 2015

In 1929, the Thinker’s Library, a series established by the
Rationalist Press Association to advance secular thinking and counter
the influence of religion in Britain, published an English translation
of the German biologist Ernst Haeckel’s 1899 book The Riddle of the
Universe. Celebrated as “the German Darwin”, Haeckel was one of the
most influential public intellectuals of the late nineteenth and early
twentieth century; The Riddle of the Universe sold half a million
copies in Germany alone, and was translated into dozens of other
languages. Hostile to Jewish and Christian traditions, Haeckel devised
his own “religion of science” called Monism, which incorporated an
anthropology that divided the human species into a hierarchy of racial
groups. Though he died in 1919, before the Nazi Party had been
founded, his ideas, and widespread influence in Germany,
unquestionably helped to create an intellectual climate in which
policies of racial slavery and genocide were able to claim a basis in
science.

The Thinker’s Library also featured works by Julian Huxley, grandson
of TH Huxley, the Victorian biologist who was known as “Darwin’s
bulldog” for his fierce defence of evolutionary theory. A proponent of
“evolutionary humanism”, which he described as “religion without
revelation”, Julian Huxley shared some of Haeckel’s views, including
advocacy of eugenics. In 1931, Huxley wrote that there was “a certain
amount of evidence that the negro is an earlier product of human
evolution than the Mongolian or the European, and as such might be
expected to have advanced less, both in body and mind”. Statements of
this kind were then commonplace: there were many in the secular
intelligentsia – including HG Wells, also a contributor to the
Thinker’s Library – who looked forward to a time when “backward”
peoples would be remade in a western mould or else vanish from the
world.

...
It has often been observed that Christianity follows changing moral
fashions, all the while believing that it stands apart from the
world. The same might be said, with more justice, of the prevalent
version of atheism. If an earlier generation of unbelievers shared the
racial prejudices of their time and elevated them to the status of
scientific truths, evangelical atheists do the same with the liberal
values to which western societies subscribe today – while looking with
contempt upon “backward” cultures that have not abandoned
religion. The racial theories promoted by atheists in the past have
been consigned to the memory hole – and today’s most influential
atheists would no more endorse racist biology than they would be seen
following the guidance of an astrologer. But they have not renounced
the conviction that human values must be based in science; now it is
liberal values which receive that accolade. There are disputes,
sometimes bitter, over how to define and interpret those values, but
their supremacy is hardly ever questioned. For 21st century atheist
missionaries, being liberal and scientific in outlook are one and the
same.

It’s a reassuringly simple equation. In fact there are no reliable
connections – whether in logic or history – between atheism, science
and liberal values. When organised as a movement and backed by the
power of the state, atheist ideologies have been an integral part of
despotic regimes that also claimed to be based in science, such as the
former Soviet Union.
...
Sam Harris, the American neuroscientist and author of The End of
Faith: Religion, Terror and the Future of Reason (2004) and The Moral
Landscape: How Science Can Determine Moral Values (2010), who was
arguably the first of the “new atheists”, illustrates this
point. Following many earlier atheist ideologues, he wants a
“scientific morality”; but whereas earlier exponents of this sort of
atheism used science to prop up values everyone would now agree were
illiberal, Harris takes for granted that what he calls a “science of
good and evil” cannot be other than liberal in content... Harris’s
militancy in asserting these values seems to be largely a 
reaction to Islamist terrorism. 
...
As society became ever more reliant on science, they had assumed,
religion would inexorably decline. No doubt the process would be
bumpy, and pockets of irrationality would linger on the margins of
modern life; but religion would dwindle away as a factor in human
conflict. The road would be long and winding. But the grand march of
secular reason would continue, with more and more societies joining
the modern west in marginalising religion. Someday, religious belief
would be no more important than personal hobbies or ethnic cuisines.

Today, it’s clear that no grand march is under way. The rise of
violent jihadism is only the most obvious example of a rejection of
secular life. 
...
It’s probably just as well that the current generation of atheists
seems to know so little of the longer history of atheist
movements. When they assert that science can bridge fact and value,
they overlook the many incompatible value-systems that have been
defended in this way. There is no more reason to think science can
determine human values today than there was at the time of Haeckel or
Huxley. None of the divergent values that atheists have from time to
time promoted has any essential connection with atheism, or with
science. How could any increase in scientific knowledge validate
values such as human equality and personal autonomy? The source of
these values is not science. In fact, as the most widely-read atheist
thinker of all time argued, these quintessential liberal values have
their origins in monotheism.
...
It’s impossible to read much contemporary polemic against religion
without the impression that for the “new atheists” the world would be
a better place if Jewish and Christian monotheism had never
existed. If only the world wasn’t plagued by these troublesome
God-botherers, they are always lamenting, liberal values would be so
much more secure. Awkwardly for these atheists, Nietzsche understood
that modern liberalism was a secular incarnation of these religious
traditions. As a classical scholar, he recognised that a mystical
Greek faith in reason had shaped the cultural matrix from which modern
liberalism emerged. Some ancient Stoics defended the ideal of a
cosmopolitan society; but this was based in the belief that humans
share in the Logos, an immortal principle of rationality that was
later absorbed into the conception of God with which we are
familiar. Nietzsche was clear that the chief sources of liberalism
were in Jewish and Christian theism: that is why he was so bitterly
hostile to these religions. He was an atheist in large part because he
rejected liberal values.
...
The far-reaching claims these thinkers have made for liberal values
can be detached from their theistic beginnings; a liberal morality
that applies to all human beings can be formulated without any mention
of religion. Or so we are continually being told. The trouble is that
it’s hard to make any sense of the idea of a universal morality
without invoking an understanding of what it is to be human that has
been borrowed from theism. The belief that the human species is a
moral agent struggling to realise its inherent possibilities – the
narrative of redemption that sustains secular humanists everywhere –
is a hollowed-out version of a theistic myth. The idea that the human
species is striving to achieve any purpose or goal – a universal state
of freedom or justice, say – presupposes a pre-Darwinian, teleological
way of thinking that has no place in science. 

------------------------------
https://www.thedailybeast.com/the-sugar-high-of-political-rhetoric
The Sugar High of Political Rhetoric
The Daily Beast · by Nick Romeo · March 4, 2017 

Rhetoric is the craft that makes facts and expertise irrelevant to
people’s decisions. It’s the art that masters all others. If the
teacher in Plato’s dialogue is right, a sufficiently skilled speaker
has the shape-shifting power to appear persuasive in any
domain. Rather than pursue the slow work of accumulating real
knowledge and expertise about a topic, the rhetorician can simply
deploy some subset of his tactics to trounce any real
expert. “Rhetoric is the only area of expertise you need to learn,”
the teacher boasts in a line that could easily be the motto of the
Trump administration. “You can ignore all the rest and still get the
better of the professionals!”

If rhetoric is what allows non-experts to dominate experts, and if
non-experts make worse decisions than experts, any healthy society
must cultivate the ability to detect and resist rhetorically seductive
frauds. The question is how.

Aristotle presents his entire Art of Rhetoric as a kind of
intellectual self-defense manual. If it’s important to know how to
defend your body from physical harm, he says, then it’s even more
vital to know how to defend your mind from rhetorical assault. Plato
uses the same metaphor of rhetoric as violence. A character in one of
Plato’s dialogues protests that a ban on rhetoric teachers would be
unfair: no one would blame a boxing instructor if one of his pupils
misused his skill and punched his parents. Similarly, the art of
rhetoric is morally neutral—capable of good or bad uses—and its
teachers deserve no blame for its misapplication.
...
The pastry maker is to the doctor what the rhetorician is to the
philosopher or expert. Rhetoric concocts pastries for the
mind. Catering to the immediate appetites of the uninformed—Mexico
will pay for the wall! There will be jobs like you can’t
believe!—rhetoric makes verbal confections designed to appeal to the
mind in the same way that a delicious pastry appeals to the
palate. The genius of this metaphor is its emphasis on pleasure. No
one has trouble understanding why even those who know better are often
overcome by the pure physical pleasure of eating sweets. Plato’s
metaphor suggests that we should regard our minds as equally
vulnerable to the seductions of pleasure.

This suggests the limits of fact-checking as a counter to
rhetoric. Minds inflamed by the pleasures of rhetoric will not be
swayed by data, facts, or arguments. These will be no more persuasive
than the admonitions of parents speaking to a child in the grips of a
strong craving for sugar.
...
It’s tempting to think that education is the only adequate defense
against the snares of rhetoric. But this is only true in an older
sense of education—one that includes moral and ethical training. If
reading Plato can help achieve this, then the ancient philosopher
really could make a difference between a century of folly and a
century of wisdom.

--------------------------------------------
https://www.nytimes.com/2017/01/13/opinion/sunday/the-real-problem-with-hypocrisy.html
The Real Problem With Hypocrisy
The New York Times · by Jillian Jordan, Roseanna Sommers and David Rand · January 13, 2017 

see: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2897313

What, exactly, is the problem with hypocrisy? When someone condemns
the behavior of others, why do we find it so objectionable if we learn
he engages in the same behavior himself?

The answer may seem self-evident. Not practicing what you preach;
lacking the willpower to live up to your own ideals; behaving in ways
you obviously know are wrong — these are clear moral failings.

Perhaps. But new research of ours, forthcoming in the journal
Psychological Science (and in collaboration with our colleague Paul
Bloom), suggests a different explanation. We contend that the reason
people dislike hypocrites is that their outspoken moralizing falsely
signals their own virtue. People object, in other words, to the
misleading implication — not to a failure of will or a weakness of
character.
....
This idea makes sense if you think about moral condemnation not as a
tool for reproaching others but as a way to boost your own
reputation. 
...
To further test our theory, we asked people to judge “non-signaling”
hypocrites: those who hypocritically condemn behaviors they engage in,
but who explicitly avoid implying anything virtuous about their
personal behavior — by saying, for instance, “I think it’s morally
wrong to waste energy, but I sometimes do it anyway.”

We found that people judged these non-signaling hypocrites much more
positively than they judged traditional hypocrites. 

---------------------------
https://digest.bps.org.uk/2016/11/14/we-have-an-unfortunate-tendency-to-assume-were-morally-superior-to-others/

We have an unfortunate tendency to assume we’re morally superior to others
digest.bps.org.uk · by Shamier · November 14, 2016 

http://spp.sagepub.com/content/early/2016/10/06/1948550616673878.abstract?papetoc

Our tendency to see ourselves as better than average – already
well-established in psychology in relation to things like driving
ability and attractiveness – applies to our sense of our own morality,
more strongly than it does to other aspects of ourselves. And the new
research shows just how irrational this really is.

----------------------------
http://www.spiked-online.com/spiked-review/article/an-enlightenment-for-grownups/18196
An Enlightenment for grownups
spiked · by Susan Neiman 

If you’re looking for a sport that commands even more international
enthusiasm than football, you might try Enlightenment-bashing. Though
we live in a world increasingly forged by new bits of technology, its
dominant rhetoric is anti-modern. Few who use that rhetoric know that
the attacks are as old as the Enlightenment itself. Edmund Burke
blamed it for the French Revolution. Karl Marx argued that the
Enlightenment furthered the demands of a few clever sons of the
bourgeoisie to privileges enjoyed by the aristocracy, thus bringing
about not universal liberation but new and subtle forms of domination
from which the world has yet to recover. Here Marx was not completely
wrong. Never quite as universal as it claimed to be, the Enlightenment
did not realise its own ideals. That’s what ideals are all about: they
always promise more than mortals who are bound in space and time can
deliver. 
...
The Enlightenment has come to stand for modernity – both for those
traditionalists whose response to modernity is nostalgia towards what
came before it, and those postmodernists whose response is ironic
distance towards everything else. There are many troubling things
about modernity, but it makes no sense to address them by creating an
Enlightenment phantom far scarier than anything that ever really
existed. For some time now, I’ve tried to strip the Enlightenment of
the clichés that surround it: that it held human nature to be perfect
and human progress to be inevitable; that reason is unlimited and
science is infallible; that faith is a worn-out answer to the
questions of the past; and that technology is the solution to all the
problems of the future.
...
Kant was living in feudal times when even enlightened rulers were
paternalistic, and ‘paternalistic’ was not yet a term of abuse. It’s
easy enough to see how feudal structures kept their subjects
infantilised. Those who think Western democracies have done away with
that sort of thing have forgotten de Toqueville’s warnings about the
power of public opinion in market-dominated societies, in which ‘the
body is left free, and the soul is enslaved safely at bay’. Without
recourse to the paternalistic and authoritarian measures available to
the guardians in Kant’s time, how might a modern democratic society
work to keep us infantilised

Think about what it means to care for an infant: exhausting as it may
be, it’s not conceptually hard. A baby who has just learned that she
can act on the world by coordinating hand and eye to grasp an object
may grasp the wrong thing: her father’s glasses, her mother’s
earrings, the knife they left on the table. But how easy it is to
distract her! All you need do is put something else in her way – a
bunch of keys will usually do it – and the baby is diverted, the
objects you don’t want her to reach now completely forgotten. As she
grows, distraction gets more difficult, but the principle remains the
same.
...
These are decisions and choices that distract all of us who have a
place in the productive, 21st-century economy, and there are so many
to be made that we tend to forget that the truly important decisions
and choices are out of our hands. It took the 17-year-old Malala to
calculate that all the world’s children could be educated for 12 years
on the profits made by the arms industry in… eight days. Most of us
will feel outrage on learning this particular statistic, but none of
us have the slightest idea of how to translate that outrage into
meaningful action. That would be a grownup question. Instead, we are
overwhelmed by the business of collecting and fumbling with toys.

Susan Neiman is director of the Einstein Forum. She is the author of
several books, including The Unity of Reason: Rereading Kant (1994);
Evil in Modern Thought: An Alternative History of Philosophy (2002);
Moral Clarity: A Guide for Grownup Idealists (2008); and Why Grow Up?
(2014).

--------------------------
https://www.wired.com/2009/01/st-thompson-14/
Clive Thompson on How More Info Leads to Less Knowledge
Wired · by Wired Staff · January 19, 2009 

Normally, we expect society to progress, amassing deeper scientific
understanding and basic facts every year. Knowledge only increases,
right?

Robert Proctor doesn't think so. A historian of science at Stanford,
Proctor points out that when it comes to many contentious subjects,
our usual relationship to information is reversed: Ignorance
increases.

He has developed a word inspired by this trend: agnotology. Derived
from the Greek root agnosis, it is "the study of culturally
constructed ignorance."

As Proctor argues, when society doesn't know something, it's often
because special interests work hard to create confusion. Anti-Obama
groups likely spent millions insisting he's a Muslim; church groups
have shelled out even more pushing creationism. The oil and auto
industries carefully seed doubt about the causes of global
warming. And when the dust settles, society knows less than it did
before.

"People always assume that if someone doesn't know something, it's
because they haven't paid attention or haven't yet figured it out,"
Proctor says. "But ignorance also comes from people literally
suppressing truth—or drowning it out—or trying to make it so confusing
that people stop caring about what's true and what's not."

---------------------------
https://www.scientificamerican.com/article/darker-skies-darker-behaviors/
Darker Skies, Darker Behaviors
Scientific American · by Jackson Lu,Julia Lee,Francesca Gino,Adam
Galinsky · January 16, 2018 

Without even realizing it, people around the world may be affected,
morally, by air pollution. Recent data on daily changes in wind
direction in Chicago and Los Angeles suggest that air pollution
increases violent crime. Using both archival and lab data, we took a
closer look at the link between air pollution and unethical behavior,
finding that the experience of air pollution increased unethical
behavior.
....
Why does pollution increase unethical behavior? We theorized that the
experience of air pollution might make people anxious and thus more
likely to behave unethically. Indeed, prior research has found that
anxiety can lead to more violent unethical behavior (such as
aggression) and non-violent unethical behavior (such as cheating on a
test to earn more money). The anxiety triggered by an economic crisis
has been found to make people more hostile and aggressive.

------------------------------
https://aeon.co/ideas/science-has-next-to-nothing-to-say-about-moral-intuitions
Science has next to nothing to say about moral intuitions – Michael Mitchell | Aeon Ideas
Aeon Magazine · by Michael Mitchell · June 22, 2016 
The psychologist Joshua Greene at Harvard led studies that asked
subjects hooked up to fMRI machines to decide whether a particular
action in a hypothetical case was appropriate or not. He and his
collaborators recorded their subjects’ responses to many cases. They
found that typically, when responding to cases in which the agent
harms someone personally (say, trolley cases in which the agent pushes
an innocent bystander over a bridge to stop the trolley from killing
five other people), the subjects showed more brain activity in regions
associated with emotions than when responding to cases in which the
agent harmed someone relatively impersonally (like trolley cases in
which the agent diverts the trolley to a track on which it will kill
one innocent bystander to stop the trolley from killing five other
people). They also found that the minority of subjects who said the
agent acted appropriately in doing harm in the personal cases took
longer to give this verdict, and experienced greater brain activity in
regions associated with reasoning than the majority who said
otherwise.

According to Greene, this indicates that our moral intuitions in
favour of deontological verdicts about cases – that you should not
harm one to save five – are generated by more emotional brain
processes responding to morally irrelevant factors, such as whether
you cause the harm directly, up close and personal, or indirectly. And
our moral intuitions in favour of consequentialist verdicts – that you
should harm one to save five – are generated by more rational
processes responsive to morally relevant factors, such as how much
harm is done for how much good.
...
Greene’s results, however, don’t offer any scientific support for
consequentialism. Nor do they say anything philosophically significant
about moral intuitions. The philosopher Selim Berker at Harvard has
offered a decisive argument why. Greene’s argument just assumes that
the factors that make a case personal – the factors that engage
relatively emotional brain processes and typically lead to
deontological intuitions – are morally irrelevant. He also assumes
that the factors the brain responds to in the relatively impersonal
cases – the factors that engage reasoning capacities and yield
consequentialist intuitions – are morally relevant. But these
assumptions are themselves moral intuitions of precisely the kind that
the argument is supposed to challenge.

Deontologists could turn the tables by claiming that the factors their
intuitions respond to are the morally relevant ones.
...
Need ethics stop until ethicists can make that argument?
Hardly. Ethics can be done in many ways. Aristotle, for one, developed
an ethical theory without appealing to intuitions. And at least since
the ironic dialogues of Socrates, philosophers have practised ethics
by meeting others where they are and trying to show them their own
hypocrisies, doubts and uncertainties. This kind of ethics aims less
at grasping foundational ethical truths than at what John Rawls called
‘proof from common ground’. And though this might seem limiting, I
suspect the task it leaves us is greater than it at first appears.

(see http://scholar.harvard.edu/sberker/publications/hthe-normative-insignificance-neuroscience)

------------------
http://nautil.us/issue/37/currents/selfishness-is-learned
Selfishness Is Learned - Issue 37: Currents - Nautilus
Nautilus · by Matthew Hutson 
The researchers worked under the assumption that snap judgments reveal
our intuitive impulses. Our intuition, apparently, is to cooperate
with others. Selfish behavior comes from thinking too much, not too
little. Rand recently verified this finding in a meta-analysis of 51
similar studies from different research groups.2 “Most people think we
are intuitively selfish,” Rand says—based on a survey he conducted—but
“our lab experiments show that making people rely more on intuition
increases cooperation.”
...
Finally, they had a breakthrough. They realized that when your default
is to betray, the benefits of deliberating—seeing a chance to
cooperate—are uncertain, depending on what your partner does. With
each partner questioning the other, and each partner factoring in the
partner’s questioning of oneself, the suspicion compounds until
there’s zero perceived benefit to deliberating. If your default is to
cooperate, however, the benefits of deliberating—occasionally acting
selfishly—accrue no matter what your partner does, and therefore
deliberation makes more sense.

So, it seems there is a firm evolutionary logic to the human instinct
to cooperate but adjust if necessary—to trust but verify. We
ordinarily cooperate with other people, because cooperation brings us
benefits, and our rational minds let us decipher when we might
occasionally gain by acting selfishly instead.

...
If you think seeing life as a set of economics games and cooperation
as self-interest in disguise sounds dismal, it is actually not so
distanced from what you might call virtue. “When I’m nice to other
people, I’m not doing it because of some kind of calculation. I’m
doing it because it feels good,” Rand says. “And the reason it feels
good, I argue, is that it is actually payoff maximizing in the long
run.”

----------------------------------
https://aeon.co/essays/there-s-no-emotion-we-ought-to-think-harder-about-than-anger
There’s no emotion we ought to think harder about than anger – Martha C Nussbaum | Aeon Essays
Aeon Magazine · by Martha C Nussbaum · July 26, 2016 

If we think closely about anger, we can begin to see why it is a
stupid way to run one’s life. A good place to begin is Aristotle’s
definition: not perfect, but useful, and a starting point for a long
Western tradition of reflection. Aristotle says that anger is a
response to a significant damage to something or someone one cares
about, and a damage that the angry person believes to have been
wrongfully inflicted. He adds that although anger is painful, it also
contains within itself a hope for payback. So: significant damage,
pertaining to one’s own values or circle of cares, and
wrongfulness. All this seems both true and uncontroversial. More
controversial, perhaps, is his idea (in which, however, all Western
philosophers who write about anger concur) that the angry person wants
some type of payback, and that this is a conceptual part of what anger
is. In other words, if you don’t want some type of payback, your
emotion is something else (grief, perhaps), but not really anger.
...

There’s no emotion we ought to think harder about than anger – Martha C Nussbaum | Aeon Essays
aeon.co 
Aeon Magazine 
7 min remaining 


There’s no emotion we ought to think harder about than anger – Martha C Nussbaum | Aeon Essays
Aeon Magazine · by Martha C Nussbaum · July 26, 2016 
There’s no emotion we ought to think harder and more clearly about than anger. Anger greets most of us every day – in our personal relationships, in the workplace, on the highway, on airline trips – and, often, in our political lives as well. Anger is both poisonous and popular. Even when people acknowledge its destructive tendencies, they still so often cling to it, seeing it as a strong emotion, connected to self-respect and manliness (or, for women, to the vindication of equality). If you react to insults and wrongs without anger you’ll be seen as spineless and downtrodden. When people wrong you, says conventional wisdom, you should use justified rage to put them in their place, exact a penalty. We could call this football politics, but we’d have to acknowledge right away that athletes, whatever their rhetoric, have to be disciplined people who know how to transcend anger in pursuit of a team goal.
If we think closely about anger, we can begin to see why it is a stupid way to run one’s life. A good place to begin is Aristotle’s definition: not perfect, but useful, and a starting point for a long Western tradition of reflection. Aristotle says that anger is a response to a significant damage to something or someone one cares about, and a damage that the angry person believes to have been wrongfully inflicted. He adds that although anger is painful, it also contains within itself a hope for payback. So: significant damage, pertaining to one’s own values or circle of cares, and wrongfulness. All this seems both true and uncontroversial. More controversial, perhaps, is his idea (in which, however, all Western philosophers who write about anger concur) that the angry person wants some type of payback, and that this is a conceptual part of what anger is. In other words, if you don’t want some type of payback, your emotion is something else (grief, perhaps), but not really anger.
Is this really right? I think so. We should understand that the wish for payback can be a very subtle wish: the angry person doesn’t need to wish to take revenge herself. She may simply want the law to do so; or even some type of divine justice. Or, she may more subtly simply want the wrongdoer’s life to go badly in future, hoping, for example, that the second marriage of her betraying spouse turns out really badly. I think if we understand the wish in this broad way, Aristotle is right: anger does contain a sort of strike-back tendency. Contemporary psychologists who study anger empirically agree with Aristotle in seeing this double movement in it, from pain to hope. 
The central puzzle is this: the payback idea does not make sense. Whatever the wrongful act was – a murder, a rape, a betrayal – inflicting pain on the wrongdoer does not help restore the thing that was lost. We think about payback all the time, and it is a deeply human tendency to think that proportionality between punishment and offence somehow makes good the offence. Only it doesn’t. Let’s say my friend has been raped. I urgently want the offender to be arrested, convicted, and punished. But really, what good will that do? Looking to the future, I might want many things: to restore my friend’s life, to prevent and deter future rapes. But harsh treatment of this particular wrongdoer might or might not achieve the latter goal. It’s an empirical matter. And usually people do not treat it as an empirical matter: they are in the grip of an idea of cosmic fitness that makes them think that blood for blood, pain for pain is the right way to go. The payback idea is deeply human, but fatally flawed as a way of making sense of the world.
There is one, and I think only one, situation in which the payback
idea does make sense. That is when I see the wrong as entirely and
only what Aristotle calls a ‘down-ranking’: a personal humiliation,
seen as entirely about relative status. If the problem is not the
injustice itself, but the way it has affected my ranking in the social
hierarchy, then I really can achieve something by humiliating the
wrongdoer: by putting him relatively lower, I put myself relatively
higher, and if status is all I care about, I don’t need to worry that
the real wellbeing problems created by the wrongful act have not been
solved.

A wronged person who is really angry, seeking to strike back, soon
arrives, I claim, at a fork in the road. Three paths lie before
her. Path one: she goes down the path of status-focus, seeing the
event as all about her and her rank. In this case her payback project
makes sense, but her normative focus is self-centred and objectionably
narrow. Path two: she focuses on the original offence (rape, murder,
etc), and seeks payback, imagining that the offender’s suffering would
actually make things better. In this case, her normative focus is on
the right things, but her thinking doesn’t make sense. Path three: if
she is rational, after exploring and rejecting these two roads, she
will notice that a third path is open to her, which is the best of
all: she can turn to the future and focus on doing whatever would make
sense, in the situation, and be really helpful. This may well include
the punishment of the wrongdoer, but in a spirit that is deterrent
rather than retaliatory.
...
Mandela’s project was political; but it has implications for many
parts of our lives: for friendship, marriage, child-rearing, being a
good colleague, driving a car. And of course it also has implications
for the way we think about what political success involves and what a
successful nation is like. Whenever we are faced with pressing moral
or political decisions, we should clear our heads, and spend some time
conducting what Mandela (citing Marcus Aurelius) referred to as
‘Conversations with Myself’. When we do, I predict, the arguments
proposed by anger will be clearly seen to be pathetic and weak, while
the voice of generosity and forward-looking reason will be strong as
well as beautiful.

----------------------------
https://dailystoic.com/how-to-meditate/

“In my experience, it’s a mistake to strive to achieve a certain
experience. Often the striving prevents you from getting wherever
you’re hoping to go. The goal in meditation is not to reach some
special state; it’s to see whatever is happening in your mind
clearly. Why is this important? Because when you see your thoughts and
feelings clearly, they have less power to yank you around.”

-----------------------
https://dailystoic.com/stoic-art-of-journaling/

Epictetus the slave. Marcus Aurelius the emperor. Seneca the power
broker and playwright. These three radically different men led
radically different lives. But they seemed to have one habit in
common: Journaling.

In one form or another, each of them did it. It would be Epictetus who
would admonish his students that philosophy was something they should
“write down day by day,” that this writing was how they “should
exercise themselves.” Seneca’s favorite time to journal was in the
evenings. When darkness had fallen and his wife had gone asleep, he
explained to a friend, “I examine my entire day and go back over what
I’ve done and said, hiding nothing from myself, passing nothing by.”
Then he would go to bed, finding that “the sleep which follows this
self-examination” was particularly sweet. And Marcus, he was the most
prodigious of journalers, and we are lucky enough that his writings
survive to us, appropriately titled, Τὰ εἰς ἑαυτόν, Ta eis heauton, or
“to himself.”
