---
title: Generative AI Wil Be a Net Productivity Drain
---

## Generative AI (and ChatGPT) Wil Be a Net Productivity Drain
While everyone is pushing out their hot takes and grabbing eyebals, I'm going to jump into the fray
with an unusual hot take: Generative AI solutions, such as ChatGPT, will be a net productivity drain.
They will not disrupt the workforce measurably and will not contribute to GDP measurably either.
I also think the hype and concern are misplaced, and are engineered to prevent a rational response
by the informed public.

_The key problem: Generative AI does _not_ know your business._

I know something about which I talk. I'm a software engineer. For over thirty years now, I've been told our very
own clever software tooling would all put us out of a job. It hasn't happened, and judging from the
rather modest uptake of ChatGPT services by programmers, this is more of the same.

The whole thesis undermining the claims of software automation surpremacy was laid out in a famous article
by Fred Brooks in 1986 - "No Silver Bullet," in _IEEE Computer_. The article targeted the claims that automated,
"no code" solutions that were being sold to business would eventually replace masses of skilled programmers. 
Fred Brooks' analysis 
proved to most readers (thirty-five years ago!) that even the most sophisticated code generation tooling
might approve productivity at the
margins, but had no chance to ever eliminate the need for professional software developers.

His central claim was the following: the chief reason software takes so much time and money to 
develop is _complexity_. Software
developent is incredibly complicated, for a variety reasons. However, one way to think about this is that
there is really just two "types" of complexity that are involved:

* "Accidental complexity". This is all of the tasks involved with writing, building and maintaining programs.
When you think of "programming," this is what you think of.

* "Essential complexity". This is the work involved with understanding the business, determining program requirements, determining which algorithms to use, and adapting all of it to the underlying business that the software supports.
People who have never worked in software development tend to be absolutely unaware of this sort of
work, but such tasks routinely take up the majority of a software developer's time. Indeed, the more senior
and high-paid the engineer, the more likely they are to spend their working hours mired in such concerns.

Brooks pointed out that all the no-code tools and code generaters were aimed at eliminating only one sort
of complexity: the
"accidental complexity." And indeed, if you look at the history of software engineering, there has been
a steady march in the decrease in accidental complexity of coded solutions. Thanks to better tooling, software
engineers are far more productive than their peers of the eighties, particularly in the more "junior" stages
of their career.

They are not, however, orders-of-magnitude more effective. The underlying business challenges
remain.

So when I look at early adopter programmers who boast that ChatGPT has made them immeasurably more productive,
I wonder what business they're in! ChatGPT does not replace the task of writing code _from scratch_;
it replaces the task of _copying_ boilerplate code from elsewhere. Indeed, the boilerplate code must
exist on the internet already - _that's why ChatGPT can write it in the first place!_. Indeed, many of the
demonstrations of "creative solutions" to programming problems shown by OpenAI have been found 
to simply duplicate 
the same problems the network was traied on. It's been shown that for actually novel problems - ones for which
solutions do not appear on the internet - ChatGPTs output is little more than garbage. The question is
why anyone should be surprised. These programs aren't intelligent! They're just very good at copying
and organizing the thoughts of others.

So: perhaps a marginally-better way of scouring the internet and putting together boilerplate code.
Useful? Yes. Revolutionary? Hardly.

Unfortunately for generative AI, the same logic applies outside of software development, to whatever
area of business you may be working in.
It would seem that for the mass of undifferentiated businesses, something like ChatGPT sounds 
like it could be immensely useful. However, the more one reflects, if a business is successful, it
succeeds because it is actually differentiated. It is specialized for a niche. Successful 
business exist because of the value
add of the firm: networks, connections, specialized knowledge, informal know-how and hard-to-replicate
technical knowledge - all the things that allow a business to thrive in competition. _This is exactly the
thing that Generative AI cannot give you._ Generative AI does not replace or extend your contact database;
it cannot understand particulars about the business you operate in; it cannot grow business differentiators.
Indeed, the only way it could become a differentiator is if somehow the technology behind ChatGPT was
exclusively available to your
firm, and that cat is clearly out of the bag.

This does not mean it is useless - it will simplify certain routine work, even routine work that "looks creative.
While it does not replace dayslong tasks of research and learning, it will
replaces a research task that used to take a half-hour of googling with a minute of queries. 
It could replaces an hour-long
search of clipart databases with a five minutes of image generation. As a professional, these are tedious tasks,
and it's good to have a progran carry those out. But it won't revolutionize your business, and anyone
whose job can be replaced is probably a low-paid uncritical hire anyway, or even an unpaid intern. It certainly
won't replace the more experienced people who pull in bigger salaries and draw expensive benefits.

The inevitable retort is that _"The AIs will only get better!" But will they?_ Further improvement over ChatGPT-4
era tooling is likely to be less significant, because such tools can only work on the same publicly available
data you yourself have access to. Claims of "emergent behavior" are ways to keep people from noticing that
dimishing returns happen _anytime_ one particular engineering technique is used in excess.
Actual meaningful improvement would require incorporating the specific domain
knowledge that is embedded into your business.

And indeed, that is a possibility. However, for that to happen, one of two things must occur:

a. You actually train your own local AI model in knowledge that you yourself have collected, complete with all of the IT work that would entail, or 
b. You upload loads of hard-earned proprietary IP into a publicly available AI brain, which will Borg all the knowledge you uploaded to it and sell it back to you _and your competitors_ in a somewhat more usable format.

If you have any business sense, you're not stupid enough to do b., and probably have the awareness that you
do not have the time and focus both do a. and run your business. That makes meaningful improvement unlikely.

So at best a marginal improvement to your business. But that's still a net positive, not a negative!
Why do I say this will be a net drag on productivity?

_The Killer Apps of Genrative AI_

There are types of businesses where this sort of AI really can improve productivty by orders of magnitude.
These are things that don't require specialized knowledge and you generally don't care about the
occasional outright falsehood. So, for those businesses, generative AI really is the "killer app" that
can revolutionize the field. The key qualities of generative AI are:
* It can produce a massive amount of output with little human intervention;
* It is sometimes indistinguishable from professional output, but generally too uncreative to be considered high-quality;
* It presents generated information as factual, no matter how wrong it may actually be.
The problem is almost all of these businesses are ethically neutral or problematic at best.

_"Content" creation_. Note that I say "content," not writing. This is the classic use of ChatGPT - the
generation of good looking and grammatically-correct but generally uninteresting and unoriginal
sort of writing that fills the internet. It will never replace long-form journalism; it will easily
replace your viral listicle. If you want plausible-sounding nonfiction that sounds like
a wikipedia article, or fiction that sounds like a composite of a thousand other works of fiction,
this fits the bill. It also explains why if try to elicit signs of intelligence from your
chatbot, you will get a composite of dialog from bad science fiction novels. 

_Ad copy_. The same qualities that make ChatGPT good for cranking out anodyne prose are also
excellent at generating reams of ad copy. The inability to tell fact from fiction is a
bug, not a feature. With a little prompting, you can even elicit outright falsehoods and lies.

_Public Relations_. Similar to ad copy, this is the generation of content skewed to a particular
viewpoint. The ability to generate a broad variety of messages, all hitting the same broad
points, will allow more realistic astroturfing initiatives, as it is more difficult to use
text similarities to trace back to the same source. The fact that you are one step removed
from the source gives you an easy out when the many mistakes in your tenditious output are pointed out.

_Misinformation_. This is perhaps the ultimate killer app. Fine-tuned AI chatbots give you the
ability to spew boatloads of
fictitious information, written in a professional confident voice. You can do it without involving any people,
with their bothersome consciences and whistleblowing tendencies.
Such engines can be modified to spread any variety of lies that can be desired. Doctored photographs,
once a time-consuming chore, can now be served up en-mass.

These business all required paid labor, which could conceivably be threatened by such AI engines.
But they are also something else - something
that has been described in other writings as "bullshit jobs." These do little to contribute to
society; indeed, some are notable drags on both economic life and the civil environment necessary
for it's proper functioning.

_In summary:_ The current incarnation of generative AI will not prove revolutionary and will
spawn a host of ills. It is unlikely to improve until it develops enough "intelligence" to
distinguish truth from error.

It can take some time to figure out if a technology is for good or ill. I like to
think of myself as an informed observer, having worked in technology a number of years. But even so
I can't boast a great track record. Some technilogies are obvious
(for instance, when I heard of Tinder shortly after getting married, I immediately thought "BAD IDEA").
Some are less obvious; I investigated cryptocurrencies a good two years
before realizing there were no buisness use cases for it
that were not criminal in one way or another. Likewise, in the mid-nineties, I concluded with a business partner that
"the internet" itself was not enough to make money off of and almost all internet startups were doomed.
I was correct, but also missed my chance to make a mint off of the bubble before it burst.

So my track record isn't great. Yet regarding the overwhelming consensus about ChatGPT and the other impressive-looking
related projects is this changes everyting: I maintain it does not.

